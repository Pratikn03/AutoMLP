{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b6f20c",
   "metadata": {},
   "source": [
    "# Data Processing Notebook\n",
    "\n",
    "This companion notebook demonstrates how the AutoML Pro pipeline imports data, runs the shared sanitisation utilities, and inspects whether additional cleaning is necessary before modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a68911",
   "metadata": {},
   "source": [
    "## 0. Environment setup\n",
    "Install the minimal requirements if you're running this outside the repo's virtualenv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ade9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r Project/requirements_min.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ea02e",
   "metadata": {},
   "source": [
    "## 1. Import helpers\n",
    "Reuse the exact Python modules used by `scripts/run_all.py` so results stay aligned with the main pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Project.utils.io import load_dataset, guess_target_column\n",
    "from Project.utils.sanitize import sanitize_columns\n",
    "from Project.utils.splits import resolve_split_plan\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e51f5",
   "metadata": {},
   "source": [
    "## 2. Load & sanitise dataset\n",
    "Set `CSV_PATH` or rely on the built-in discovery logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: override with a specific CSV\n",
    "data = sanitize_columns(load_dataset(max_rows=2000))\n",
    "target_col = guess_target_column(data)\n",
    "print(f\"Detected target column: {target_col}\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616a931",
   "metadata": {},
   "source": [
    "## 3. Missing values / dtype audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "profile = pd.DataFrame({\n",
    "    'dtype': data.dtypes,\n",
    "    'missing_pct': data.isna().mean() * 100,\n",
    "    'unique_vals': data.nunique()\n",
    "}).sort_values('missing_pct', ascending=False)\n",
    "profile.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a4cb6",
   "metadata": {},
   "source": [
    "## 4. Train/validation splits\n",
    "Demonstrate that the registry-driven split plan works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_plan = resolve_split_plan(csv_path=None)\n",
    "folds = list(split_plan.split(data.drop(columns=[target_col]), data[target_col].tolist(), n_splits=3, seed=42, is_classification=True))\n",
    "print(f\"Generated {len(folds)} folds via {split_plan.strategy} strategy\")\n",
    "[f\"train={len(tr)}, valid={len(val)}\" for tr, val in folds]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ff965",
   "metadata": {},
   "source": [
    "## 5. Optional: pipe into analysis utilities\n",
    "Call the Python modules directly: `Project.analysis.summarize_all.main()` regenerates the summary CSVs, and `Project.analysis.plot_comparisons.main()` produces the figures showcased in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e45ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Project.analysis import summarize_all, plot_comparisons\n",
    "\n",
    "# Uncomment to regenerate reports/metrics based on current dataset selection\n",
    "# summarize_all.main()\n",
    "# plot_comparisons.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa631cd",
   "metadata": {},
   "source": [
    "Feel free to duplicate this notebook inside `notebooks/data_processing/` and tailor it per dataset; each variant will demonstrate the data preparation story for your presentation."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
