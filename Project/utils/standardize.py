"""Utility helpers for standardizing metric formats, IO, and reporting.

This module centralizes small concerns that were previously re-implemented
across training & analysis scripts:
  * Directory creation
  * Normalisation of metric/column names (old vs new schema)
  * Leaderboard updating (idempotent + safe)
  * Lightweight validation + warnings (no hard failures unless essential)

Design notes:
  * `framework` argument is Optional: some legacy CSVs lack it; we inject.
  * We do NOT force presence of rarely‑computed metrics (e.g. precision) –
    they are only added if provided. This prevents seas of NaNs and keeps
    downstream summaries meaningful.
  * Public surface kept tiny; analysis scripts should import only from here.
"""
from __future__ import annotations

import os
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import pandas as pd

# Core metrics we recognise. Ordered for display.
STANDARD_METRICS: List[str] = [
    "f1_macro",  # primary optimisation
    "accuracy",
    "roc_auc_ovr",
    "avg_precision_ovr",
    "fit_time_sec",
    "predict_time_sec",
    # optional / rarely present below (only retained if supplied)
    "f1", "precision", "recall",
]

ALIAS_MAP = {
    "f1_score": "f1",
    "f1score": "f1",
    "accuracy_score": "accuracy",
    "roc_auc": "roc_auc_ovr",
    "avg_prec": "avg_precision_ovr",
    "average_precision": "avg_precision_ovr",
}

REQUIRED_DIRS = [
    "reports",
    "reports/metrics",
    "reports/ablations",
    "figures",
    "figures/ablations",
    "artifacts",
]


def ensure_directories() -> Dict[str, Path]:
    """Ensure required directories exist; return mapping for convenience."""
    out = {}
    for d in REQUIRED_DIRS:
        p = Path(d)
        p.mkdir(parents=True, exist_ok=True)
        out[d] = p
    return out


def _coerce_framework_column(df: pd.DataFrame, framework: Optional[str]) -> pd.DataFrame:
    if "model" in df.columns and "framework" not in df.columns:
        df = df.rename(columns={"model": "framework"})
    if "framework" not in df.columns:
        df["framework"] = framework if framework is not None else "UNKNOWN"
    return df


def standardize_metrics(df: pd.DataFrame, framework: Optional[str]) -> pd.DataFrame:
    """Return a sanitized copy of a metrics dataframe.

    We do not forcibly append *all* STANDARD_METRICS – only those discovered
    or derivable – to avoid misleading aggregates of NaNs. Downstream code
    should guard for absent metrics (presence => column in df.columns).
    """
    if df is None or df.empty:
        return pd.DataFrame()

    df = df.copy()
    df = _coerce_framework_column(df, framework)
    # Apply alias mapping
    rename = {c: ALIAS_MAP[c] for c in df.columns if c in ALIAS_MAP}
    if rename:
        df = df.rename(columns=rename)
    # Drop duplicate rows that can arise from repeated concatenations
    df = df.drop_duplicates().reset_index(drop=True)
    return df


def load_metrics(metrics_dir: str = "reports/metrics") -> Dict[str, pd.DataFrame]:
    """Load and concatenate fold-level metrics generated by experiment runs."""
    metrics_path = Path(metrics_dir)
    results: Dict[str, pd.DataFrame] = {}
    grouped = defaultdict(list)

    if metrics_path.is_dir():
        for csv_path in metrics_path.glob("*_folds.csv"):
            try:
                raw = pd.read_csv(csv_path)
            except Exception as exc:  # pragma: no cover - defensive
                print(f"[standardize] Warning: failed reading {csv_path.name}: {exc}")
                continue

            framework_name: Optional[str] = None
            if "framework" in raw.columns and raw["framework"].nunique(dropna=True) == 1:
                framework_name = str(raw["framework"].iloc[0])
            if not framework_name:
                framework_name = csv_path.stem.replace("_folds", "")
                raw["framework"] = framework_name

            grouped[framework_name].append(standardize_metrics(raw, framework_name))

    for framework_name, frames in grouped.items():
        if not frames:
            continue
        concatenated = pd.concat(frames, ignore_index=True)
        framework_key = str(framework_name)
        results[framework_key] = concatenated

    lb_path = Path("reports/leaderboard.csv")
    if lb_path.is_file():
        try:
            lb = pd.read_csv(lb_path)
            results["leaderboard"] = standardize_metrics(lb, None)
        except Exception as e:
            print(f"[standardize] Warning: failed loading leaderboard: {e}")
    return results


def _present_metrics(cols: Iterable[str]) -> List[str]:
    # preserve STANDARD_METRICS order then append any others
    present = [m for m in STANDARD_METRICS if m in cols]
    extras = [c for c in cols if c not in present and c not in {"framework", "fold", "seed"}]
    return present + sorted(extras)


def update_leaderboard(df: pd.DataFrame, framework: str) -> None:
    """Merge (idempotently) the mean row for a framework into leaderboard.

    Only aggregates over metrics actually present to avoid NaN pollution.
    """
    lb_path = Path("reports/leaderboard.csv")
    cols = _present_metrics(df.columns)
    means: Dict[str, Any] = {m: df[m].mean() for m in cols if m in df.columns}
    means["framework"] = framework
    new_row = pd.DataFrame([means])

    if lb_path.is_file():
        try:
            lb = pd.read_csv(lb_path)
            lb = standardize_metrics(lb, None)
        except Exception:  # pragma: no cover
            lb = pd.DataFrame()
    else:
        lb = pd.DataFrame()

    if not lb.empty and "framework" in lb.columns:
        lb = lb[~lb.framework.eq(framework)]
        lb = pd.concat([lb, new_row], ignore_index=True)
    else:
        lb = new_row
    lb.to_csv(lb_path, index=False)


def save_metrics(df: pd.DataFrame, framework: str, metrics_dir: str = "reports/metrics") -> None:
    Path(metrics_dir).mkdir(parents=True, exist_ok=True)
    df_std = standardize_metrics(df, framework)
    path = Path(metrics_dir) / f"{framework}_folds.csv"
    df_std.to_csv(path, index=False)
    update_leaderboard(df_std, framework)


def ascii_table(rows: List[Dict[str, object]], headers: List[str]) -> str:
    """Render a very small plain ASCII table (no external deps)."""
    if not rows:
        return "<empty>"
    widths = {h: max(len(h), *(len(f"{r.get(h,'')}") for r in rows)) for h in headers}
    sep = "+" + "+".join("-" * (widths[h] + 2) for h in headers) + "+"
    def fmt_row(r):
        return "|" + "|".join(f" {str(r.get(h, '')):<{widths[h]}} " for h in headers) + "|"
    out = [sep, fmt_row({h: h for h in headers}), sep]
    out.extend(fmt_row(r) for r in rows)
    out.append(sep)
    return "\n".join(out)


__all__ = [
    "STANDARD_METRICS",
    "ensure_directories",
    "standardize_metrics",
    "load_metrics",
    "save_metrics",
    "update_leaderboard",
    "ascii_table",
]